{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Business function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "#import tensorflow\n",
    "#import keras\n",
    "import wordcloud\n",
    "import nltk\n",
    "import inspect\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import RSLPStemmer #Stemmer for portugese words.\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import missingno as msno\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "import string\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,roc_auc_score,roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "#import folium\n",
    "#from folium.plugins import Fullscreen\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\d.cadavid141\\\\Documents\\\\Coisas Daniela\\\\201920\\\\201920\\\\00_Bases\\\\brazilian-ecommerce'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(\"/Users/danielacadavid/Documents/Universidad/Maestria/201920/00_Bases/brazilian-ecommerce/\")\n",
    "os.chdir(\"C:\\\\Users\\\\d.cadavid141\\\\Documents\\\\Coisas Daniela\\\\201920\\\\201920\\\\00_Bases\\\\brazilian-ecommerce\\\\\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41753, 8)\n",
      "(99441, 5)\n",
      "(99441, 8)\n",
      "(112650, 7)\n",
      "['Unnamed: 0', 'review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n"
     ]
    }
   ],
   "source": [
    "order_items=pd.read_csv('olist_order_items_dataset.csv')\n",
    "customers=pd.read_csv('olist_customers_dataset.csv')\n",
    "ordenes = pd.read_csv('olist_orders_dataset.csv')\n",
    "orders=pd.read_csv('data_tratada_v_nao.csv')\n",
    "print(orders.shape)\n",
    "print(customers.shape)\n",
    "print(ordenes.shape)\n",
    "print(order_items.shape)\n",
    "print(list(orders.columns))\n",
    "print(list(customers.columns))\n",
    "print(list(ordenes.columns))\n",
    "print(list(order_items.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_id', 'review_score', 'order_id', 'review_comment_message']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_orders = ['review_id','review_score','order_id','review_comment_message']\n",
    "orders = orders[cols_orders]\n",
    "list(orders.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_id', 'price', 'freight_value']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_ordenes_it = ['order_id','price','freight_value']\n",
    "order_items = order_items[cols_ordenes_it]\n",
    "list(order_items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_id', 'customer_id']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_ordenes = ['order_id','customer_id']\n",
    "ordenes = ordenes[cols_ordenes]\n",
    "list(ordenes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_id', 'customer_unique_id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_cust = ['customer_id','customer_unique_id']\n",
    "customers = customers[cols_cust]\n",
    "list(customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41753, 6)\n"
     ]
    }
   ],
   "source": [
    "# Joining order and items datasets\n",
    "orders_items_1 = orders.merge(order_items, on='order_id', how='left')\n",
    "orders_items   = orders_items_1.drop_duplicates(keep='last',subset=['order_id','review_id'])\n",
    "#valor_orden = orders_items['order_id','review_comment_message','price','freight_value']\n",
    "print(orders_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41753, 7)\n"
     ]
    }
   ],
   "source": [
    "# Joining order and items datasets\n",
    "orders_items_cust_1 = orders_items.merge(ordenes, on='order_id', how='left')\n",
    "orders_items_cust   = orders_items_cust_1.drop_duplicates(keep='last',subset=['order_id','review_id'])\n",
    "#valor_orden = orders_items['order_id','review_comment_message','price','freight_value']\n",
    "print(orders_items_cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41753, 8)\n"
     ]
    }
   ],
   "source": [
    "# Joining order and items datasets\n",
    "orders_items_cust_1     = orders_items_cust.merge(customers, on='customer_id', how='left')\n",
    "orders_items_customer   = orders_items_cust_1.drop_duplicates(keep='last',subset=['order_id','review_id','customer_unique_id'])\n",
    "print(orders_items_customer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vezes=orders_items_customer['customer_unique_id'].value_counts().rename_axis('customer_unique_id').reset_index(name='counts')\n",
    "#vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41753, 9)\n"
     ]
    }
   ],
   "source": [
    "# Times a client buys\n",
    "orders_items_cust_1     = orders_items_customer.merge(vezes, on='customer_unique_id', how='left')\n",
    "orders_items_customer   = orders_items_cust_1.drop_duplicates(keep='last',subset=['order_id','review_id','customer_unique_id'])\n",
    "print(orders_items_customer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### ACA SE CREA EL BOW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(orders_items_customer.review_comment_message).toarray()\n",
    "X = pd.DataFrame(X_tfidf, columns = list(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data to have a mean of ~0 and a variance of 1\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the class label\n",
    "bin_edges = [0, 2, 5]\n",
    "bin_names = ['0', '1']\n",
    "orders_items_customer['class'] = pd.cut(orders_items_customer['review_score'] , bins=bin_edges, labels=bin_names)\n",
    "#orders = orders.iloc[:, np.r_[0, 1, 3, 4, 2, 5,6]\n",
    "y = orders_items_customer['class'].values\n",
    "Y_tf = y.astype(int)\n",
    "#Y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename='finalized_model_pca.sav'\n",
    "pca = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_pca=pca.transform(X_std)\n",
    "X_val_mod=pd.DataFrame(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "\n",
    "vars_gb = 245\n",
    "vars_rf = 20\n",
    "vars_lr = 2849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[[vars_usar]]\n",
    "X_GB = X_val_mod.iloc[:,0:vars_gb]\n",
    "X_RF = X_val_mod.iloc[:,0:vars_rf]\n",
    "X_LR = X_val_mod.iloc[:,0:vars_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8674900720951692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "filename='finalized_model_pca_gb.sav'\n",
    "gb_model = pickle.load(open(filename, 'rb'))\n",
    "gb_roc_auc=roc_auc_score(Y_tf, gb_model.predict(X_GB))\n",
    "gb_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119984830826976"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "filename='finalized_model_pca_rf.sav'\n",
    "rf_model = pickle.load(open(filename, 'rb'))\n",
    "rf_roc_auc=roc_auc_score(Y_tf, rf_model.predict(X_RF))\n",
    "rf_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724502908580312"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "filename='finalized_model_pca_lr.sav'\n",
    "lr_model = pickle.load(open(filename, 'rb'))\n",
    "rf_roc_auc=roc_auc_score(Y_tf, lr_model.predict(X_LR))\n",
    "rf_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes de la funcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred = pd.DataFrame(gb_model.predict(X_GB), columns = ['pred_gb'])\n",
    "rf_pred = pd.DataFrame(rf_model.predict(X_RF), columns = ['pred_rf'])\n",
    "lr_pred = pd.DataFrame(lr_model.predict(X_LR), columns = ['pred_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price e mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_items_customer['valor']=orders_items_customer['price']+orders_items_customer['freight_value']\n",
    "orders_items_customer['p_n']=orders_items_customer['valor']/max(orders_items_customer['valor'])\n",
    "\n",
    "orders_items_customer['mu_hi']  = orders_items_customer['p_n'].apply(lambda x: 0.5+0.5*x  if x<=0.5  else 0.75+0.25*x)\n",
    "orders_items_customer['mu_low'] = orders_items_customer['p_n'].apply(lambda x: 0.4+0.5*x  if x<=0.5  else 0.65+0.25*x)\n",
    "\n",
    "\n",
    "orders_items_customer['mu_high_counts'] = orders_items_customer['mu_hi']  * orders_items_customer['counts']\n",
    "orders_items_customer['mu_low_counts']  = orders_items_customer['mu_low'] * orders_items_customer['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = orders_items_customer[['mu_high_counts','mu_low_counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt=pd.DataFrame(Y_tf.transpose(), columns=['Y_real'])\n",
    "\n",
    "frames = [yt,gb_pred,rf_pred,lr_pred,cost]\n",
    "#result = pd.concat(frames)\n",
    "costo_pca=pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "costo_pca.to_csv(\"C:\\\\Users\\\\d.cadavid141\\\\Documents\\\\Coisas Daniela\\\\201920\\\\201920\\\\00_Bases\\\\brazilian-ecommerce\\\\costo_pca.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costo autom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costo_d(x):\n",
    "    if x['Y_real']==x['pred_gb'] and x['pred_gb']==0:\n",
    "        return x['mu_low_counts']\n",
    "    \n",
    "def costo_a(x):\n",
    "    if x['Y_real']!=x['pred_gb'] and x['pred_gb']==1:\n",
    "        return x['mu_high_counts']\n",
    "    \n",
    "def costo_b(x):\n",
    "    if x['Y_real']==1 and x['pred_gb']==0:\n",
    "        return 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = costo_pca.apply(costo_d, axis=1)\n",
    "a = costo_pca.apply(costo_a, axis=1)\n",
    "b = costo_pca.apply(costo_b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Function PCA_GB=-2714.01\n"
     ]
    }
   ],
   "source": [
    "D=d.sum()\n",
    "A=a.sum()\n",
    "B=b.sum()\n",
    "\n",
    "Costo_GB=A+B-D\n",
    "print(f'Soft Function PCA_GB='+str(round(Costo_GB,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
